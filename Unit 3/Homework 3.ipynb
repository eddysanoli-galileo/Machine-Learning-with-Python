{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3\n",
    "-------\n",
    "\n",
    "### 1. Neural Networks\n",
    "\n",
    "#### Feed Forward Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [[9.99999694e-01 3.05902227e-07]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Optional\n",
    "\n",
    "# Input array\n",
    "x : np.ndarray = np.asarray([[3, 14]]).T\n",
    "\n",
    "# Get the number of input samples\n",
    "no_samples : int = x.shape[1]\n",
    "\n",
    "# Add an additional row of ones to represent the bias when\n",
    "# multiplying the input with the first set of weights\n",
    "constant : np.ndarray = np.ones((1, no_samples))\n",
    "\n",
    "# We add the constant to the input array\n",
    "# (The axis option must be added or the output array will be one dimensional)\n",
    "x = np.append(x, constant, axis=0)\n",
    "\n",
    "# Layer 1: Weights\n",
    "W : np.ndarray = np.asarray([\n",
    "    [ 1,  0, -1],\n",
    "    [ 0,  1, -1],\n",
    "    [-1,  0, -1],\n",
    "    [ 0, -1, -1]\n",
    "])\n",
    "\n",
    "# Layer 2: Weights\n",
    "V : np.ndarray = np.asarray([\n",
    "    [ 1,  1,  1,  1, 0],\n",
    "    [-1, -1, -1, -1, 2]\n",
    "])\n",
    "\n",
    "# Hidden layer activation function\n",
    "relu = lambda z: np.maximum(z, 0)\n",
    "\n",
    "# Softmax activation function\n",
    "# (Add the axis to the sum to support more samples)\n",
    "softmax = lambda u: np.exp(relu(u)) / np.sum(np.exp(relu(u)), axis=1)\n",
    "\n",
    "# Layer: Hidden Layer\n",
    "fz : np.ndarray = relu(np.dot(x.T, W.T))\n",
    "\n",
    "# Add bias (A column of 1's) to hidden layer output\n",
    "fz = np.append(fz.T, constant, axis=0)\n",
    "\n",
    "# Layer: Output Layer\n",
    "fu : np.ndarray = softmax(np.dot(fz.T, V.T))\n",
    "print(\"Output:\", fu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Boundaries\n",
    "\n",
    "In this problem we visualize the â€œdecision boundaries\" in $x$-space, corresponding to the four hidden units. These are the lines in $x$-space where the values of $z_1, z_2, z_3, z_4$ are exactly zero. Plot the decision boundaries of the four hidden units using the parameters of $W$ provided above.\n",
    "\n",
    "$$\n",
    "\\displaystyle z_1 = x_1 W_{11} + x_2 W_{21} + W_{01}\\\\\n",
    "\\displaystyle z_2 = x_1 W_{12} + x_2 W_{22} + W_{02}\\\\\n",
    "\\displaystyle z_3 = x_1 W_{13} + x_2 W_{23} + W_{03}\\\\\n",
    "\\displaystyle z_4 = x_1 W_{13} + x_2 W_{23} + W_{03}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = np.linspace(-10, 10, 100)\n",
    "x2 = np.linspace(-10, 10, 100)\n",
    "\n",
    "x1_0 = (-W[0,2] - W[0,1]*x2) / W[0,0]\n",
    "x2_1 = (-W[1,2] - W[1,0]*x1) / W[1,1]\n",
    "x1_2 = (-W[2,2] - W[2,1]*x2) / W[2,0]\n",
    "x2_3 = (-W[3,2] - W[3,0]*x1) / W[3,1]\n",
    "\n",
    "plt.plot(x1_0, x2)\n",
    "plt.plot(x1, x2_1)\n",
    "plt.plot(x1_2, x2)\n",
    "plt.plot(x1, x2_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output of Neural Network\n",
    "\n",
    "Using the same matrix $V$ as above, what is the value of $o_1$ (accurate to at least three decimal places if responding numerically) in the following three cases?\n",
    "\n",
    "- Assuming that $f(z_1) + f(z_2) + f(z_3) + f(z_4) = 1$\n",
    "- Assuming that $f(z_1) + f(z_2) + f(z_3) + f(z_4) = 0$\n",
    "- Assuming that $f(z_1) + f(z_2) + f(z_3) + f(z_4) = 3$\n",
    "\n",
    "**Answer**\n",
    "\n",
    "The first row of the V matrix is just a bunch of ones with a zero at the end. That means that each of the outputs of the hidden layer will be multiplied by one and then a bias of zero will be added. This means that the logits that are fed into the first output neuron will consist of the following\n",
    "\n",
    "$$f(z_1)*1 + f(z_2)*1 + f(z_3)*1 + f(z_4)*1 + 0$$\n",
    "$$f(z_1)*-1 + f(z_2)*-1 + f(z_3)*-1 + f(z_4)*-1 + 2$$\n",
    "\n",
    "Which basically boils down to a sum of all the outputs of the hidden layer for the first logit, and the sum of all outputs negated and with 2 added to the negated sum. Since we know the value for the sum of the hidden layer outputs for each case, we now know the different values that will be hypothetically fed into the output layer activation function (softmax)\n",
    "\n",
    "- Case 1: Softmax([1, -1+2]) = Softmax([1, 1])\n",
    "- Case 2: Softmax([0, -0+2]) = Softmax([0, 2])\n",
    "- Case 3: Softmax([3, -3+2]) = Softmax([3, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: [[0.5 0.5]]\n",
      "Case 2: [[0.11920292 0.88079708]]\n",
      "Case 3: [[0.95257413 0.04742587]]\n"
     ]
    }
   ],
   "source": [
    "# To get the value of the first output neuron, you need to fetch\n",
    "# the first value of the printed array\n",
    "print(\"Case 1:\", softmax([[1, 1]]))\n",
    "print(\"Case 2:\", softmax([[0, 2]]))\n",
    "print(\"Case 3:\", softmax([[3, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LSTM\n",
    "\n",
    "#### LSTM States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: 0.0\n",
      "Index 1: 0.0\n",
      "Index 2: 1.0\n",
      "Index 3: -1.0\n",
      "Index 4: 1.0\n",
      "Index 5: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Input sequence\n",
    "x : np.ndarray = np.asarray([0, 0, 1, 1, 1, 0])\n",
    "\n",
    "# LSTM Parameters\n",
    "W_fh = 0\n",
    "W_ih = 0\n",
    "W_oh = 0\n",
    "W_fx = 0\n",
    "W_ix = 100\n",
    "W_ox = 100\n",
    "W_ch = -100\n",
    "W_cx = 50\n",
    "\n",
    "# Biases\n",
    "bf = -100\n",
    "bi = 100\n",
    "bo = 0\n",
    "bc = 0\n",
    "\n",
    "# Initial Conditions\n",
    "h_t = 0\n",
    "c_t = 0\n",
    "\n",
    "# Sigmoid function\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "# LSTM Neuron Declaration\n",
    "def LSTM(x, h_t, c_t):\n",
    "\n",
    "    # Go through each time step of the input sequence\n",
    "    for idx, x_t in enumerate(x):\n",
    "\n",
    "        # Forget gate\n",
    "        f_t = sigmoid(W_fh * h_t + W_fx * x_t + bf)\n",
    "        \n",
    "        # Input gate\n",
    "        i_t = sigmoid(W_ix * h_t + W_ix * x_t + bi)\n",
    "\n",
    "        # Output gate\n",
    "        o_t = sigmoid(W_oh * h_t + W_ox * x_t + bo)\n",
    "\n",
    "        # Memory Cell\n",
    "        c_t = f_t * c_t + i_t * np.tanh(W_ch * h_t + W_cx * x_t + bc)\n",
    "\n",
    "        # Visible State\n",
    "        h_t = o_t * np.tanh(c_t)\n",
    "\n",
    "        # We present the visible state in each timestep as a rounded\n",
    "        # value that doesn't have any decimals\n",
    "        print(f\"Index {idx}:\", np.round(h_t, 0))\n",
    "\n",
    "\n",
    "# Call the LSTM function with the initial sequence\n",
    "LSTM(x, h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM States 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: 1.0\n",
      "Index 1: -1.0\n",
      "Index 2: 0.0\n",
      "Index 3: 1.0\n",
      "Index 4: -1.0\n"
     ]
    }
   ],
   "source": [
    "# New input sequence\n",
    "x : np.ndarray = np.asarray([1, 1, 0, 1, 1])\n",
    "\n",
    "# Initialize the memory cell and visible state\n",
    "c_t = 0\n",
    "h_t = 0\n",
    "\n",
    "# Print the visible state each timestep\n",
    "LSTM(x, h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Backpropagation\n",
    "\n",
    "#### Computing the Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Machine_Learning_with_Python-7V858pgh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbf55fd141a929e96d217693ff943f340da010ee827d3bb7b01df8ee1539f1d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
