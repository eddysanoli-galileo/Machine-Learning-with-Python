{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: Digit Recognition\n",
    "\n",
    "Good programmers can use neural nets. Great programmers can make them. This section will guide you through the implementation of a simple neural net with an architecture as shown in the figure below. You will implement the net from scratch (you will probably never do this again, don't worry) so that you later feel confident about using libraries. We provide some skeleton code in neural_nets.py for you to fill in.\n",
    "\n",
    "![neural_net](../Media/images_neuralnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddysanoli\\.virtualenvs\\Machine_Learning_with_Python-7V858pgh\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Activation Functions\n",
    "\n",
    "#### Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectified_linear_unit(x):\n",
    "    \"\"\" Returns the ReLU of x, or the maximum between 0 and x.\"\"\"\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectified_linear_unit_derivative(x):\n",
    "    \"\"\" Returns the derivative of ReLU.\"\"\"\n",
    "\n",
    "    x[x > 0] = 1\n",
    "    x[x <= 0] = 0\n",
    "\n",
    "    # ReLu returns 1 for all positive values and 0 for all negative values\n",
    "    # (Returns 0 when the value is equal to 0 as well)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### 4. Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_activation(x):\n",
    "    \"\"\" Linear function, returns input as is. \"\"\"\n",
    "    return x\n",
    "\n",
    "def output_layer_activation_derivative(x):\n",
    "    \"\"\" Returns the derivative of a linear function: 1. \"\"\"\n",
    "    return 1\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \"\"\"\n",
    "        Contains the following functions:\n",
    "            -train: tunes parameters of the neural network based on error obtained from forward propagation.\n",
    "            -predict: predicts the label of a feature vector based on the class's parameters.\n",
    "            -train_neural_network: trains a neural network over all the data points for the specified number of epochs during initialization of the class.\n",
    "            -test_neural_network: uses the parameters specified at the time in order to test that the neural network classifies the points given in testing_points within a margin of error.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # DO NOT CHANGE PARAMETERS (Initialized to floats instead of ints)\n",
    "        self.input_to_hidden_weights = np.matrix('1. 1.; 1. 1.; 1. 1.')  # (3,2)\n",
    "        self.hidden_to_output_weights = np.matrix('1. 1. 1.')\n",
    "        self.biases = np.matrix('0.; 0.; 0.')\n",
    "        self.learning_rate = .001\n",
    "        self.epochs_to_train = 10\n",
    "        self.training_points = [((2,1), 10), ((3,3), 21), ((4,5), 32), ((6, 6), 42)]\n",
    "        self.testing_points = [(1,1), (2,2), (3,3), (5,5), (10,10)]\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "\n",
    "    def train(self, x1 : float, x2: float, y):\n",
    "\n",
    "        ### Forward propagation ###\n",
    "        input_values = np.matrix([[x1],[x2]]) # 2 by 1\n",
    "\n",
    "        # Calculate the input and activation of the hidden layer\n",
    "        hidden_layer_weighted_input = np.dot(self.input_to_hidden_weights, input_values) + self.biases  # (3,2) * (2x1) = (3,1) + (3,1) = (3,1)\n",
    "        hidden_layer_activation = rectified_linear_unit(hidden_layer_weighted_input)                    # (3,1)\n",
    "\n",
    "        output = np.dot(self.hidden_to_output_weights, hidden_layer_activation)                         # (1,3) * (3,1) = (1,1)\n",
    "        activated_output = output_layer_activation(output)\n",
    "\n",
    "        ### Backpropagation ###\n",
    "\n",
    "        # Compute gradients\n",
    "        output_layer_error = (y - activated_output)                                                                                 # Derivative of cost function\n",
    "        hidden_layer_error = self.hidden_to_output_weights.T * output_layer_activation_derivative(output) *  output_layer_error     # (3 by 1 matrix)\n",
    "\n",
    "        bias_gradients = hidden_layer_error * 1                                                     # Derivative of Z with respect of the bias is 1 (Z = W*a + b) \n",
    "        hidden_to_output_weight_gradients = np.dot(output_layer_error, hidden_layer_activation.T)   # Derivative of Z with respect of the weights is the weighted input of the layer (Z' = a)\n",
    "        input_to_hidden_weight_gradients = np.dot(hidden_layer_error, input_values.T)\n",
    "        \n",
    "        # print(bias_gradients.shape)\n",
    "        # print(input_to_hidden_weight_gradients.shape)\n",
    "        # print(hidden_to_output_weight_gradients.shape)\n",
    "        # print(\"======================\")\n",
    "\n",
    "        # Use gradients to adjust weights and biases using gradient descent\n",
    "        self.biases = self.biases - self.learning_rate * bias_gradients\n",
    "        self.input_to_hidden_weights = self.input_to_hidden_weights - self.learning_rate * input_to_hidden_weight_gradients\n",
    "        self.hidden_to_output_weights = self.hidden_to_output_weights - self.learning_rate * hidden_to_output_weight_gradients\n",
    "\n",
    "    # ============================================================\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "\n",
    "        input_values = np.matrix([[x1],[x2]])\n",
    "        print(input_values.shape)\n",
    "        print(self.input_to_hidden_weights.shape)\n",
    "\n",
    "        # Compute output for a single input(should be same as the forward propagation in training)\n",
    "        hidden_layer_weighted_input = np.dot(self.input_to_hidden_weights, input_values) + self.biases\n",
    "        hidden_layer_activation = rectified_linear_unit(hidden_layer_weighted_input)\n",
    "        output = np.dot(self.hidden_to_output_weights, hidden_layer_activation)\n",
    "\n",
    "        activated_output = output_layer_activation(output)\n",
    "        return activated_output.item()\n",
    "\n",
    "    # Run this to train your neural network once you complete the train method\n",
    "    def train_neural_network(self):\n",
    "\n",
    "        for epoch in range(self.epochs_to_train):\n",
    "            for x,y in self.training_points:\n",
    "                self.train(x[0], x[1], y)\n",
    "\n",
    "    # Run this to test your neural network implementation for correctness after it is trained\n",
    "    def test_neural_network(self):\n",
    "\n",
    "        for point in self.testing_points:\n",
    "            print(\"Point,\", point, \"Prediction,\", self.predict(point[0], point[1]))\n",
    "            if abs(self.predict(point[0], point[1]) - 7*point[0]) < 0.1:\n",
    "                print(\"Test Passed\")\n",
    "            else:\n",
    "                print(\"Point \", point[0], point[1], \" failed to be predicted correctly.\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(3, 2)\n",
      "Point, (1, 1) Prediction, -inf\n",
      "(2, 1)\n",
      "(3, 2)\n",
      "Point  1 1  failed to be predicted correctly.\n"
     ]
    }
   ],
   "source": [
    "x = NeuralNetwork()\n",
    "x.train_neural_network()\n",
    "x.test_neural_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fully-Connected Neural Networks\n",
    "\n",
    "#### Training and Testing Accuracy Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1855.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.366998 | Train accuracy: 0.897025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 5053.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.179281 | Val accuracy:   0.947527\n",
      "-------------\n",
      "Epoch 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1815.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.175322 | Train accuracy: 0.948818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.126170 | Val accuracy:   0.966076\n",
      "-------------\n",
      "Epoch 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1819.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.123239 | Train accuracy: 0.965230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.104606 | Val accuracy:   0.970922\n",
      "-------------\n",
      "Epoch 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1757.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.095654 | Train accuracy: 0.973085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4921.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.092678 | Val accuracy:   0.973095\n",
      "-------------\n",
      "Epoch 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1783.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.077786 | Train accuracy: 0.977882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.084781 | Val accuracy:   0.975434\n",
      "-------------\n",
      "Epoch 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1810.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.065020 | Train accuracy: 0.981884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 5054.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.079922 | Val accuracy:   0.977106\n",
      "-------------\n",
      "Epoch 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1821.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.055229 | Train accuracy: 0.984903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.076733 | Val accuracy:   0.976604\n",
      "-------------\n",
      "Epoch 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1779.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.047383 | Train accuracy: 0.987478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.074332 | Val accuracy:   0.977607\n",
      "-------------\n",
      "Epoch 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1753.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.040840 | Train accuracy: 0.989256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.072652 | Val accuracy:   0.978610\n",
      "-------------\n",
      "Epoch 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1759.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.035235 | Train accuracy: 0.991146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 5342.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.070931 | Val accuracy:   0.978944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:00<00:00, 5114.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test set:0.07416471567711806 Accuracy on test set: 0.9772636217948718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import _pickle as cPickle, gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from mnist.utils import *\n",
    "from mnist.part2_mnist.train_utils import batchify_data, run_epoch, train_model\n",
    "\n",
    "# Specify seed for deterministic behavior, then shuffle. \n",
    "# Do not change seed for official submissions to edx\n",
    "np.random.seed(12321)  # for reproducibility\n",
    "torch.manual_seed(12321)  # for reproducibility\n",
    "\n",
    "# Load the dataset\n",
    "num_classes = 10\n",
    "X_train, y_train, X_test, y_test = get_MNIST_data()\n",
    "\n",
    "# Split into train and dev\n",
    "dev_split_index = int(9 * len(X_train) / 10)\n",
    "X_dev = X_train[dev_split_index:]\n",
    "y_dev = y_train[dev_split_index:]\n",
    "X_train = X_train[:dev_split_index]\n",
    "y_train = y_train[:dev_split_index]\n",
    "\n",
    "permutation = np.array([i for i in range(len(X_train))])\n",
    "np.random.shuffle(permutation)\n",
    "X_train = [X_train[i] for i in permutation]\n",
    "y_train = [y_train[i] for i in permutation]\n",
    "\n",
    "# Split dataset into batches\n",
    "batch_size = 32\n",
    "train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "#################################\n",
    "## Model specification TODO\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "lr=0.1\n",
    "momentum=0\n",
    "##################################\n",
    "\n",
    "train_model(train_batches, dev_batches, model, lr=lr, momentum=momentum)\n",
    "\n",
    "## Evaluate the model on test data\n",
    "loss, accuracy = run_epoch(test_batches, model.eval(), None)\n",
    "\n",
    "print (\"Loss on test set:\"  + str(loss) + \" Accuracy on test set: \" + str(accuracy))\n",
    "\n",
    "# ===========================\n",
    "# INITIAL ARCHITECTURE\n",
    "\n",
    "#                                        TEST\n",
    "#                       ----------------------------------------\n",
    "# Baseline:             Accuracy = 0.920472 / Loss = 0.267226\n",
    "# Batch Size 64:        Accuracy = 0.931490 / Loss = 0.24238465\n",
    "# Learning Rate 0.01:   Accuracy = 0.920673 / Loss = 0.278865\n",
    "# Momentum 0.9:         Accuracy = 0.859375 / Loss = 0.541848\n",
    "# Leaky ReLU:           Accuracy = 0.920773 / Loss = 0.2689\n",
    "\n",
    "# ============================\n",
    "# HIDDEN REPRESENTATION WITH 128 NEURONS\n",
    "\n",
    "#                           VALIDATION              TEST\n",
    "#                       ----------------------------------------\n",
    "# Baseline:             Accuracy = 0.978275   /   0.977163\n",
    "# Batch Size 64:        Accuracy = 0.976983   /   0.97435\n",
    "# Learning Rate 0.01:   Accuracy = 0.955047   /   0.942708\n",
    "# Momentum 0.9:         Accuracy = 0.963402   /   0.962139\n",
    "# Leaky ReLU:           Accuracy = 0.978944   /   0.977263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Convolutional Neural Networks\n",
    "\n",
    "#### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 107.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.244268 | Train accuracy: 0.923477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 258.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.060793 | Val accuracy:   0.983122\n",
      "-------------\n",
      "Epoch 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 107.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.078232 | Train accuracy: 0.976400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 259.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.043116 | Val accuracy:   0.988302\n",
      "-------------\n",
      "Epoch 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 106.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.057196 | Train accuracy: 0.983088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 247.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.041414 | Val accuracy:   0.986798\n",
      "-------------\n",
      "Epoch 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:16<00:00, 104.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.044947 | Train accuracy: 0.986477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 261.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.034902 | Val accuracy:   0.988302\n",
      "-------------\n",
      "Epoch 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 106.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.039600 | Train accuracy: 0.987737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 251.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.033554 | Val accuracy:   0.989639\n",
      "-------------\n",
      "Epoch 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:16<00:00, 103.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.033319 | Train accuracy: 0.989497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 260.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.035708 | Val accuracy:   0.989138\n",
      "-------------\n",
      "Epoch 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 107.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.028448 | Train accuracy: 0.991053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 264.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.036412 | Val accuracy:   0.988803\n",
      "-------------\n",
      "Epoch 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 108.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.024920 | Train accuracy: 0.991979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 262.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.032701 | Val accuracy:   0.990976\n",
      "-------------\n",
      "Epoch 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:16<00:00, 103.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.022843 | Train accuracy: 0.992590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 256.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.036936 | Val accuracy:   0.990809\n",
      "-------------\n",
      "Epoch 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:15<00:00, 106.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.020617 | Train accuracy: 0.993387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 250.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.036291 | Val accuracy:   0.991477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:01<00:00, 259.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test set:0.02825509168977046 Accuracy on test set: 0.9902844551282052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import _pickle as c_pickle, gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from mnist.utils  import *\n",
    "from mnist.part2_mnist.train_utils import batchify_data, run_epoch, train_model, Flatten\n",
    "\n",
    "# Specify seed for deterministic behavior, then shuffle. Do not change seed for official submissions to edx\n",
    "np.random.seed(12321)  # for reproducibility\n",
    "torch.manual_seed(12321)\n",
    "\n",
    "# Load the dataset\n",
    "num_classes = 10\n",
    "X_train, y_train, X_test, y_test = get_MNIST_data()\n",
    "\n",
    "# We need to rehape the data back into a 1x28x28 image\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, 28, 28))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, 28, 28))\n",
    "\n",
    "# Split into train and dev\n",
    "dev_split_index = int(9 * len(X_train) / 10)\n",
    "X_dev = X_train[dev_split_index:]\n",
    "y_dev = y_train[dev_split_index:]\n",
    "X_train = X_train[:dev_split_index]\n",
    "y_train = y_train[:dev_split_index]\n",
    "\n",
    "permutation = np.array([i for i in range(len(X_train))])\n",
    "np.random.shuffle(permutation)\n",
    "X_train = [X_train[i] for i in permutation]\n",
    "y_train = [y_train[i] for i in permutation]\n",
    "\n",
    "# Split dataset into batches\n",
    "batch_size = 32\n",
    "train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "#################################\n",
    "## Model specification TODO\n",
    "model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (3, 3)),         # Channels: 1 (Monochrome image). 32 Image channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),             # Image reduced from 28x28 to \n",
    "            nn.Conv2d(32, 64, (3, 3)),        # The last Conv2d layer outputs 32 image channels. Here they are expanded to 64 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1600, 128),              # Input\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "##################################\n",
    "\n",
    "train_model(train_batches, dev_batches, model, nesterov=True)\n",
    "\n",
    "## Evaluate the model on test data\n",
    "loss, accuracy = run_epoch(test_batches, model.eval(), None)\n",
    "\n",
    "print (\"Loss on test set:\"  + str(loss) + \" Accuracy on test set: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Overlapping, multi-digit MNIST\n",
    "\n",
    "#### Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Archivos\\Educación\\Posgrado\\Data Science (Universidad Galileo)\\2022 (MITx)\\Machine Learning with Python\\Unit 3\\Project 3\\mnist\\part2_twodigit\\train_utils.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  'x': torch.tensor(x_data[i:i + batch_size],\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Archivos\\Educación\\Posgrado\\Data Science (Universidad Galileo)\\2022 (MITx)\\Machine Learning with Python\\Unit 3\\Project 3\\Project 3.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=60'>61</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m12321\u001b[39m)  \u001b[39m# for reproducibility\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=61'>62</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m12321\u001b[39m)  \u001b[39m# for reproducibility\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=62'>63</a>\u001b[0m main()\n",
      "\u001b[1;32me:\\Archivos\\Educación\\Posgrado\\Data Science (Universidad Galileo)\\2022 (MITx)\\Machine Learning with Python\\Unit 3\\Project 3\\Project 3.ipynb Cell 15\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=51'>52</a>\u001b[0m model \u001b[39m=\u001b[39m MLP(input_dimension) \u001b[39m# TODO add proper layers to MLP class above\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=53'>54</a>\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=54'>55</a>\u001b[0m train_model(train_batches, dev_batches, model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=56'>57</a>\u001b[0m \u001b[39m## Evaluate the model on test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Archivos/Educaci%C3%B3n/Posgrado/Data%20Science%20%28Universidad%20Galileo%29/2022%20%28MITx%29/Machine%20Learning%20with%20Python/Unit%203/Project%203/Project%203.ipynb#ch0000013?line=57'>58</a>\u001b[0m loss, acc \u001b[39m=\u001b[39m run_epoch(test_batches, model\u001b[39m.\u001b[39meval(), \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Archivos\\Educación\\Posgrado\\Data Science (Universidad Galileo)\\2022 (MITx)\\Machine Learning with Python\\Unit 3\\Project 3\\mnist\\part2_twodigit\\train_utils.py:41\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_data, dev_data, model, lr, momentum, nesterov, n_epochs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"Train a model for N epochs given data and hyper-params.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# We optimize with SGD\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mSGD(model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49mlr, momentum\u001b[39m=\u001b[39;49mmomentum, nesterov\u001b[39m=\u001b[39;49mnesterov)\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     44\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch))\n",
      "File \u001b[1;32mc:\\Users\\eddysanoli\\.virtualenvs\\Machine_Learning_with_Python-7V858pgh\\lib\\site-packages\\torch\\optim\\sgd.py:105\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m nesterov \u001b[39mand\u001b[39;00m (momentum \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m dampening \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m \u001b[39msuper\u001b[39;49m(SGD, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n",
      "File \u001b[1;32mc:\\Users\\eddysanoli\\.virtualenvs\\Machine_Learning_with_Python-7V858pgh\\lib\\site-packages\\torch\\optim\\optimizer.py:49\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     47\u001b[0m param_groups \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(params)\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(param_groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moptimizer got an empty parameter list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(param_groups[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m):\n\u001b[0;32m     51\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mnist.part2_twodigit.train_utils import batchify_data, run_epoch, train_model, Flatten\n",
    "import mnist.part2_twodigit.utils_multiMNIST as U\n",
    "path_to_data_dir = './mnist/Datasets/'\n",
    "use_mini_dataset = True\n",
    "\n",
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 42, 28 # input image dimensions\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        # TODO initialize model layers here\n",
    "\n",
    "    def forward(self, x):\n",
    "        xf = self.flatten(x)\n",
    "\n",
    "        # TODO use model layers to predict the two digits\n",
    "\n",
    "        return out_first_digit, out_second_digit\n",
    "\n",
    "def main():\n",
    "    X_train, y_train, X_test, y_test = U.get_data(path_to_data_dir, use_mini_dataset)\n",
    "\n",
    "    # Split into train and dev\n",
    "    dev_split_index = int(9 * len(X_train) / 10)\n",
    "    X_dev = X_train[dev_split_index:]\n",
    "    y_dev = [y_train[0][dev_split_index:], y_train[1][dev_split_index:]]\n",
    "    X_train = X_train[:dev_split_index]\n",
    "    y_train = [y_train[0][:dev_split_index], y_train[1][:dev_split_index]]\n",
    "\n",
    "    permutation = np.array([i for i in range(len(X_train))])\n",
    "    np.random.shuffle(permutation)\n",
    "    X_train = [X_train[i] for i in permutation]\n",
    "    y_train = [[y_train[0][i] for i in permutation], [y_train[1][i] for i in permutation]]\n",
    "\n",
    "    # Split dataset into batches\n",
    "    train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "    dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "    test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "    # Load model\n",
    "    input_dimension = img_rows * img_cols\n",
    "    model = MLP(input_dimension) # TODO add proper layers to MLP class above\n",
    "\n",
    "    # Train\n",
    "    train_model(train_batches, dev_batches, model)\n",
    "\n",
    "    ## Evaluate the model on test data\n",
    "    loss, acc = run_epoch(test_batches, model.eval(), None)\n",
    "    print('Test loss1: {:.6f}  accuracy1: {:.6f}  loss2: {:.6f}   accuracy2: {:.6f}'.format(loss[0], acc[0], loss[1], acc[1]))\n",
    "\n",
    "np.random.seed(12321)  # for reproducibility\n",
    "torch.manual_seed(12321)  # for reproducibility\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Machine_Learning_with_Python-7V858pgh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbf55fd141a929e96d217693ff943f340da010ee827d3bb7b01df8ee1539f1d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
