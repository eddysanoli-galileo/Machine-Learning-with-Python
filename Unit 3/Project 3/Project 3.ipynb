{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: Digit Recognition\n",
    "\n",
    "Good programmers can use neural nets. Great programmers can make them. This section will guide you through the implementation of a simple neural net with an architecture as shown in the figure below. You will implement the net from scratch (you will probably never do this again, don't worry) so that you later feel confident about using libraries. We provide some skeleton code in neural_nets.py for you to fill in.\n",
    "\n",
    "![neural_net](../Media/images_neuralnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddysanoli\\.virtualenvs\\Machine_Learning_with_Python-7V858pgh\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Activation Functions\n",
    "\n",
    "#### Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectified_linear_unit(x):\n",
    "    \"\"\" Returns the ReLU of x, or the maximum between 0 and x.\"\"\"\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectified_linear_unit_derivative(x):\n",
    "    \"\"\" Returns the derivative of ReLU.\"\"\"\n",
    "\n",
    "    x[x > 0] = 1\n",
    "    x[x <= 0] = 0\n",
    "\n",
    "    # ReLu returns 1 for all positive values and 0 for all negative values\n",
    "    # (Returns 0 when the value is equal to 0 as well)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### 4. Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_activation(x):\n",
    "    \"\"\" Linear function, returns input as is. \"\"\"\n",
    "    return x\n",
    "\n",
    "def output_layer_activation_derivative(x):\n",
    "    \"\"\" Returns the derivative of a linear function: 1. \"\"\"\n",
    "    return 1\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \"\"\"\n",
    "        Contains the following functions:\n",
    "            -train: tunes parameters of the neural network based on error obtained from forward propagation.\n",
    "            -predict: predicts the label of a feature vector based on the class's parameters.\n",
    "            -train_neural_network: trains a neural network over all the data points for the specified number of epochs during initialization of the class.\n",
    "            -test_neural_network: uses the parameters specified at the time in order to test that the neural network classifies the points given in testing_points within a margin of error.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # DO NOT CHANGE PARAMETERS (Initialized to floats instead of ints)\n",
    "        self.input_to_hidden_weights = np.matrix('1. 1.; 1. 1.; 1. 1.')  # (3,2)\n",
    "        self.hidden_to_output_weights = np.matrix('1. 1. 1.')\n",
    "        self.biases = np.matrix('0.; 0.; 0.')\n",
    "        self.learning_rate = .001\n",
    "        self.epochs_to_train = 10\n",
    "        self.training_points = [((2,1), 10), ((3,3), 21), ((4,5), 32), ((6, 6), 42)]\n",
    "        self.testing_points = [(1,1), (2,2), (3,3), (5,5), (10,10)]\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "\n",
    "    def train(self, x1 : float, x2: float, y):\n",
    "\n",
    "        ### Forward propagation ###\n",
    "        input_values = np.matrix([[x1],[x2]]) # 2 by 1\n",
    "\n",
    "        # Calculate the input and activation of the hidden layer\n",
    "        hidden_layer_weighted_input = np.dot(self.input_to_hidden_weights, input_values) + self.biases  # (3,2) * (2x1) = (3,1) + (3,1) = (3,1)\n",
    "        hidden_layer_activation = rectified_linear_unit(hidden_layer_weighted_input)                    # (3,1)\n",
    "\n",
    "        output = np.dot(self.hidden_to_output_weights, hidden_layer_activation)                         # (1,3) * (3,1) = (1,1)\n",
    "        activated_output = output_layer_activation(output)\n",
    "\n",
    "        ### Backpropagation ###\n",
    "\n",
    "        # Compute gradients\n",
    "        output_layer_error = (y - activated_output)                                                                                 # Derivative of cost function\n",
    "        hidden_layer_error = self.hidden_to_output_weights.T * output_layer_activation_derivative(output) *  output_layer_error     # (3 by 1 matrix)\n",
    "\n",
    "        bias_gradients = hidden_layer_error * 1                                                     # Derivative of Z with respect of the bias is 1 (Z = W*a + b) \n",
    "        hidden_to_output_weight_gradients = np.dot(output_layer_error, hidden_layer_activation.T)   # Derivative of Z with respect of the weights is the weighted input of the layer (Z' = a)\n",
    "        input_to_hidden_weight_gradients = np.dot(hidden_layer_error, input_values.T)\n",
    "        \n",
    "        # print(bias_gradients.shape)\n",
    "        # print(input_to_hidden_weight_gradients.shape)\n",
    "        # print(hidden_to_output_weight_gradients.shape)\n",
    "        # print(\"======================\")\n",
    "\n",
    "        # Use gradients to adjust weights and biases using gradient descent\n",
    "        self.biases = self.biases - self.learning_rate * bias_gradients\n",
    "        self.input_to_hidden_weights = self.input_to_hidden_weights - self.learning_rate * input_to_hidden_weight_gradients\n",
    "        self.hidden_to_output_weights = self.hidden_to_output_weights - self.learning_rate * hidden_to_output_weight_gradients\n",
    "\n",
    "    # ============================================================\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "\n",
    "        input_values = np.matrix([[x1],[x2]])\n",
    "        print(input_values.shape)\n",
    "        print(self.input_to_hidden_weights.shape)\n",
    "\n",
    "        # Compute output for a single input(should be same as the forward propagation in training)\n",
    "        hidden_layer_weighted_input = np.dot(self.input_to_hidden_weights, input_values) + self.biases\n",
    "        hidden_layer_activation = rectified_linear_unit(hidden_layer_weighted_input)\n",
    "        output = np.dot(self.hidden_to_output_weights, hidden_layer_activation)\n",
    "\n",
    "        activated_output = output_layer_activation(output)\n",
    "        return activated_output.item()\n",
    "\n",
    "    # Run this to train your neural network once you complete the train method\n",
    "    def train_neural_network(self):\n",
    "\n",
    "        for epoch in range(self.epochs_to_train):\n",
    "            for x,y in self.training_points:\n",
    "                self.train(x[0], x[1], y)\n",
    "\n",
    "    # Run this to test your neural network implementation for correctness after it is trained\n",
    "    def test_neural_network(self):\n",
    "\n",
    "        for point in self.testing_points:\n",
    "            print(\"Point,\", point, \"Prediction,\", self.predict(point[0], point[1]))\n",
    "            if abs(self.predict(point[0], point[1]) - 7*point[0]) < 0.1:\n",
    "                print(\"Test Passed\")\n",
    "            else:\n",
    "                print(\"Point \", point[0], point[1], \" failed to be predicted correctly.\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(3, 2)\n",
      "Point, (1, 1) Prediction, -inf\n",
      "(2, 1)\n",
      "(3, 2)\n",
      "Point  1 1  failed to be predicted correctly.\n"
     ]
    }
   ],
   "source": [
    "x = NeuralNetwork()\n",
    "x.train_neural_network()\n",
    "x.test_neural_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fully-Connected Neural Networks\n",
    "\n",
    "#### Training and Testing Accuracy Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1855.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.366998 | Train accuracy: 0.897025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 5053.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.179281 | Val accuracy:   0.947527\n",
      "-------------\n",
      "Epoch 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1815.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.175322 | Train accuracy: 0.948818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.126170 | Val accuracy:   0.966076\n",
      "-------------\n",
      "Epoch 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1819.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.123239 | Train accuracy: 0.965230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.104606 | Val accuracy:   0.970922\n",
      "-------------\n",
      "Epoch 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1757.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.095654 | Train accuracy: 0.973085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4921.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.092678 | Val accuracy:   0.973095\n",
      "-------------\n",
      "Epoch 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1783.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.077786 | Train accuracy: 0.977882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.084781 | Val accuracy:   0.975434\n",
      "-------------\n",
      "Epoch 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1810.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.065020 | Train accuracy: 0.981884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 5054.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.079922 | Val accuracy:   0.977106\n",
      "-------------\n",
      "Epoch 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1821.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.055229 | Train accuracy: 0.984903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.076733 | Val accuracy:   0.976604\n",
      "-------------\n",
      "Epoch 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1779.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.047383 | Train accuracy: 0.987478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.074332 | Val accuracy:   0.977607\n",
      "-------------\n",
      "Epoch 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1753.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.040840 | Train accuracy: 0.989256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 4794.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.072652 | Val accuracy:   0.978610\n",
      "-------------\n",
      "Epoch 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [00:00<00:00, 1759.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.035235 | Train accuracy: 0.991146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 5342.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:   0.070931 | Val accuracy:   0.978944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:00<00:00, 5114.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test set:0.07416471567711806 Accuracy on test set: 0.9772636217948718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import _pickle as cPickle, gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from mnist.utils import *\n",
    "from mnist.part2_mnist.train_utils import batchify_data, run_epoch, train_model\n",
    "\n",
    "# Specify seed for deterministic behavior, then shuffle. \n",
    "# Do not change seed for official submissions to edx\n",
    "np.random.seed(12321)  # for reproducibility\n",
    "torch.manual_seed(12321)  # for reproducibility\n",
    "\n",
    "# Load the dataset\n",
    "num_classes = 10\n",
    "X_train, y_train, X_test, y_test = get_MNIST_data()\n",
    "\n",
    "# Split into train and dev\n",
    "dev_split_index = int(9 * len(X_train) / 10)\n",
    "X_dev = X_train[dev_split_index:]\n",
    "y_dev = y_train[dev_split_index:]\n",
    "X_train = X_train[:dev_split_index]\n",
    "y_train = y_train[:dev_split_index]\n",
    "\n",
    "permutation = np.array([i for i in range(len(X_train))])\n",
    "np.random.shuffle(permutation)\n",
    "X_train = [X_train[i] for i in permutation]\n",
    "y_train = [y_train[i] for i in permutation]\n",
    "\n",
    "# Split dataset into batches\n",
    "batch_size = 32\n",
    "train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "#################################\n",
    "## Model specification TODO\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "lr=0.1\n",
    "momentum=0\n",
    "##################################\n",
    "\n",
    "train_model(train_batches, dev_batches, model, lr=lr, momentum=momentum)\n",
    "\n",
    "## Evaluate the model on test data\n",
    "loss, accuracy = run_epoch(test_batches, model.eval(), None)\n",
    "\n",
    "print (\"Loss on test set:\"  + str(loss) + \" Accuracy on test set: \" + str(accuracy))\n",
    "\n",
    "# ===========================\n",
    "# INITIAL ARCHITECTURE\n",
    "\n",
    "#                                        TEST\n",
    "#                       ----------------------------------------\n",
    "# Baseline:             Accuracy = 0.920472 / Loss = 0.267226\n",
    "# Batch Size 64:        Accuracy = 0.931490 / Loss = 0.24238465\n",
    "# Learning Rate 0.01:   Accuracy = 0.920673 / Loss = 0.278865\n",
    "# Momentum 0.9:         Accuracy = 0.859375 / Loss = 0.541848\n",
    "# Leaky ReLU:           Accuracy = 0.920773 / Loss = 0.2689\n",
    "\n",
    "# ============================\n",
    "# HIDDEN REPRESENTATION WITH 128 NEURONS\n",
    "\n",
    "#                           VALIDATION              TEST\n",
    "#                       ----------------------------------------\n",
    "# Baseline:             Accuracy = 0.978275   /   0.977163\n",
    "# Batch Size 64:        Accuracy = 0.976983   /   0.97435\n",
    "# Learning Rate 0.01:   Accuracy = 0.955047   /   0.942708\n",
    "# Momentum 0.9:         Accuracy = 0.963402   /   0.962139\n",
    "# Leaky ReLU:           Accuracy = 0.978944   /   0.977263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Convolutional Neural Networks\n",
    "\n",
    "#### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as c_pickle, gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from mnist.utils  import *\n",
    "from mnist.part2_mnist.train_utils import batchify_data, run_epoch, train_model, Flatten\n",
    "\n",
    "# Specify seed for deterministic behavior, then shuffle. Do not change seed for official submissions to edx\n",
    "np.random.seed(12321)  # for reproducibility\n",
    "torch.manual_seed(12321)\n",
    "\n",
    "# Load the dataset\n",
    "num_classes = 10\n",
    "X_train, y_train, X_test, y_test = get_MNIST_data()\n",
    "\n",
    "# We need to rehape the data back into a 1x28x28 image\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, 28, 28))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, 28, 28))\n",
    "\n",
    "# Split into train and dev\n",
    "dev_split_index = int(9 * len(X_train) / 10)\n",
    "X_dev = X_train[dev_split_index:]\n",
    "y_dev = y_train[dev_split_index:]\n",
    "X_train = X_train[:dev_split_index]\n",
    "y_train = y_train[:dev_split_index]\n",
    "\n",
    "permutation = np.array([i for i in range(len(X_train))])\n",
    "np.random.shuffle(permutation)\n",
    "X_train = [X_train[i] for i in permutation]\n",
    "y_train = [y_train[i] for i in permutation]\n",
    "\n",
    "# Split dataset into batches\n",
    "batch_size = 32\n",
    "train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "#################################\n",
    "## Model specification TODO\n",
    "model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (3, 3)),         # Channels: 1 (Monochrome image). 32 Image channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),             # Image reduced from 28x28 to \n",
    "            nn.Conv2d(32, 64, (3, 3)),        # The last Conv2d layer outputs 32 image channels. Here they are expanded to 64 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1600, 128),              # Input\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "##################################\n",
    "\n",
    "train_model(train_batches, dev_batches, model, nesterov=True)\n",
    "\n",
    "## Evaluate the model on test data\n",
    "loss, accuracy = run_epoch(test_batches, model.eval(), None)\n",
    "\n",
    "print (\"Loss on test set:\"  + str(loss) + \" Accuracy on test set: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Overlapping, multi-digit MNIST\n",
    "\n",
    "#### Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mnist.part2_twodigit.train_utils import batchify_data, run_epoch, train_model, Flatten\n",
    "import mnist.part2_twodigit.utils_multiMNIST as U\n",
    "path_to_data_dir = './mnist/Datasets/'\n",
    "use_mini_dataset = True\n",
    "\n",
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 42, 28 # input image dimensions\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = nn.Linear(input_dimension, 64)\n",
    "\n",
    "        # 20 output classes (Pairs of 10 possible digits different digits)\n",
    "        self.linear2 = nn.Linear(64, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xf = self.flatten(x)\n",
    "\n",
    "        # A ReLu activation function because... why not?\n",
    "        xl1 = self.linear1(xf)\n",
    "\n",
    "        # You need to use softmax because its a multi-class classification problem\n",
    "        xl2 = self.linear2(xl1)\n",
    "\n",
    "        # Re-structure the output as two separate variables\n",
    "        out_first_digit = xl2[:, :10]\n",
    "        out_second_digit = xl2[:, 10:]\n",
    "\n",
    "        return out_first_digit, out_second_digit\n",
    "\n",
    "def main():\n",
    "    X_train, y_train, X_test, y_test = U.get_data(path_to_data_dir, use_mini_dataset)\n",
    "    print(y_train[0].shape, y_train[1].shape)\n",
    "\n",
    "    # Split into train and dev\n",
    "    dev_split_index = int(9 * len(X_train) / 10)\n",
    "    X_dev = X_train[dev_split_index:]\n",
    "    y_dev = [y_train[0][dev_split_index:], y_train[1][dev_split_index:]]\n",
    "    X_train = X_train[:dev_split_index]\n",
    "    y_train = [y_train[0][:dev_split_index], y_train[1][:dev_split_index]]\n",
    "\n",
    "    permutation = np.array([i for i in range(len(X_train))])\n",
    "    np.random.shuffle(permutation)\n",
    "    X_train = [X_train[i] for i in permutation]\n",
    "    y_train = [[y_train[0][i] for i in permutation], [y_train[1][i] for i in permutation]]\n",
    "\n",
    "    # Split dataset into batches\n",
    "    train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "    dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "    test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "    # Load model\n",
    "    input_dimension = img_rows * img_cols\n",
    "    model = MLP(input_dimension) # TODO add proper layers to MLP class above\n",
    "\n",
    "    # Train\n",
    "    train_model(train_batches, dev_batches, model)\n",
    "\n",
    "    ## Evaluate the model on test data\n",
    "    loss, acc = run_epoch(test_batches, model.eval(), None)\n",
    "    print('Test loss1: {:.6f}  accuracy1: {:.6f}  loss2: {:.6f}   accuracy2: {:.6f}'.format(loss[0], acc[0], loss[1], acc[1]))\n",
    "\n",
    "np.random.seed(12321)  # for reproducibility\n",
    "torch.manual_seed(12321)  # for reproducibility\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Archivos\\Educación\\Posgrado\\Data Science (Universidad Galileo)\\2022 (MITx)\\Machine Learning with Python\\Unit 3\\Project 3\\mnist\\part2_twodigit\\train_utils.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  'x': torch.tensor(x_data[i:i + batch_size],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.821744  accuracy1: 0.731067 | loss2: 0.868528  accuracy2: 0.705488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 87.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.212937  accuracy1: 0.936744 | loss2: 0.249888  accuracy2: 0.922379\n",
      "-------------\n",
      "Epoch 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.277024  accuracy1: 0.912784 | loss2: 0.326594  accuracy2: 0.891070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 80.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.140246  accuracy1: 0.956401 | loss2: 0.160948  accuracy2: 0.947329\n",
      "-------------\n",
      "Epoch 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.202184  accuracy1: 0.938000 | loss2: 0.244636  accuracy2: 0.919512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 86.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.124825  accuracy1: 0.960433 | loss2: 0.130571  accuracy2: 0.959425\n",
      "-------------\n",
      "Epoch 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.162735  accuracy1: 0.951151 | loss2: 0.197964  accuracy2: 0.934831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 91.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.096605  accuracy1: 0.971018 | loss2: 0.104877  accuracy2: 0.968246\n",
      "-------------\n",
      "Epoch 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.135950  accuracy1: 0.957935 | loss2: 0.168082  accuracy2: 0.945257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 87.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.091181  accuracy1: 0.973034 | loss2: 0.089136  accuracy2: 0.970514\n",
      "-------------\n",
      "Epoch 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 37.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.115992  accuracy1: 0.964246 | loss2: 0.148391  accuracy2: 0.952541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 85.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.088006  accuracy1: 0.973286 | loss2: 0.081496  accuracy2: 0.971018\n",
      "-------------\n",
      "Epoch 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.103298  accuracy1: 0.967749 | loss2: 0.129339  accuracy2: 0.957073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 86.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.078259  accuracy1: 0.976058 | loss2: 0.078203  accuracy2: 0.973034\n",
      "-------------\n",
      "Epoch 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.090895  accuracy1: 0.971919 | loss2: 0.119039  accuracy2: 0.960854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:01<00:00, 40.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.074605  accuracy1: 0.977319 | loss2: 0.072699  accuracy2: 0.975806\n",
      "-------------\n",
      "Epoch 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:18<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.082930  accuracy1: 0.973532 | loss2: 0.106901  accuracy2: 0.964746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 81.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.074024  accuracy1: 0.977067 | loss2: 0.072612  accuracy2: 0.975554\n",
      "-------------\n",
      "Epoch 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 35.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.077913  accuracy1: 0.976340 | loss2: 0.097153  accuracy2: 0.967388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 86.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.069849  accuracy1: 0.980847 | loss2: 0.067006  accuracy2: 0.978831\n",
      "-------------\n",
      "Epoch 11:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.069537  accuracy1: 0.977730 | loss2: 0.089413  accuracy2: 0.969501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 86.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.072650  accuracy1: 0.977823 | loss2: 0.070378  accuracy2: 0.978327\n",
      "-------------\n",
      "Epoch 12:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.063722  accuracy1: 0.980038 | loss2: 0.082481  accuracy2: 0.972337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 82.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.071792  accuracy1: 0.978579 | loss2: 0.068295  accuracy2: 0.976310\n",
      "-------------\n",
      "Epoch 13:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.059943  accuracy1: 0.980399 | loss2: 0.075474  accuracy2: 0.975117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 90.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.070934  accuracy1: 0.978327 | loss2: 0.057146  accuracy2: 0.980847\n",
      "-------------\n",
      "Epoch 14:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 39.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.054315  accuracy1: 0.982874 | loss2: 0.070090  accuracy2: 0.976284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 92.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.072688  accuracy1: 0.979587 | loss2: 0.063578  accuracy2: 0.979083\n",
      "-------------\n",
      "Epoch 15:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 39.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.052298  accuracy1: 0.983402 | loss2: 0.067280  accuracy2: 0.977035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 93.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.073164  accuracy1: 0.980091 | loss2: 0.059399  accuracy2: 0.980595\n",
      "-------------\n",
      "Epoch 16:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 39.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.047330  accuracy1: 0.984987 | loss2: 0.060950  accuracy2: 0.978509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 89.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.075289  accuracy1: 0.979083 | loss2: 0.061226  accuracy2: 0.979335\n",
      "-------------\n",
      "Epoch 17:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.043419  accuracy1: 0.985459 | loss2: 0.059985  accuracy2: 0.979148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 81.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.065354  accuracy1: 0.983115 | loss2: 0.058397  accuracy2: 0.980847\n",
      "-------------\n",
      "Epoch 18:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 37.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.041996  accuracy1: 0.986015 | loss2: 0.055111  accuracy2: 0.980955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 84.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.066594  accuracy1: 0.982611 | loss2: 0.060197  accuracy2: 0.980847\n",
      "-------------\n",
      "Epoch 19:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.038634  accuracy1: 0.987544 | loss2: 0.051527  accuracy2: 0.982707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 86.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.070924  accuracy1: 0.981351 | loss2: 0.057170  accuracy2: 0.979335\n",
      "-------------\n",
      "Epoch 20:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.037148  accuracy1: 0.987906 | loss2: 0.051058  accuracy2: 0.982596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 89.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.069249  accuracy1: 0.981855 | loss2: 0.056713  accuracy2: 0.981351\n",
      "-------------\n",
      "Epoch 21:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 38.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.034849  accuracy1: 0.988601 | loss2: 0.044885  accuracy2: 0.983819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 91.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.081609  accuracy1: 0.979587 | loss2: 0.060057  accuracy2: 0.979839\n",
      "-------------\n",
      "Epoch 22:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 38.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.033033  accuracy1: 0.989268 | loss2: 0.042783  accuracy2: 0.984959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 96.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.069787  accuracy1: 0.983367 | loss2: 0.052537  accuracy2: 0.983115\n",
      "-------------\n",
      "Epoch 23:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:13<00:00, 41.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.029561  accuracy1: 0.990631 | loss2: 0.039795  accuracy2: 0.985960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 89.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.069037  accuracy1: 0.983619 | loss2: 0.054760  accuracy2: 0.981099\n",
      "-------------\n",
      "Epoch 24:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:14<00:00, 39.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.028170  accuracy1: 0.990909 | loss2: 0.036678  accuracy2: 0.986988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 97.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.077449  accuracy1: 0.981855 | loss2: 0.056224  accuracy2: 0.982611\n",
      "-------------\n",
      "Epoch 25:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:13<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.026189  accuracy1: 0.990964 | loss2: 0.040427  accuracy2: 0.985737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 94.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.080519  accuracy1: 0.981603 | loss2: 0.049570  accuracy2: 0.983619\n",
      "-------------\n",
      "Epoch 26:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:13<00:00, 41.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.026640  accuracy1: 0.990881 | loss2: 0.035259  accuracy2: 0.987016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 96.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.073372  accuracy1: 0.983619 | loss2: 0.050028  accuracy2: 0.982863\n",
      "-------------\n",
      "Epoch 27:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:13<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.024795  accuracy1: 0.991687 | loss2: 0.030134  accuracy2: 0.989713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 99.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.077170  accuracy1: 0.983367 | loss2: 0.053747  accuracy2: 0.983871\n",
      "-------------\n",
      "Epoch 28:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:15<00:00, 36.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.024006  accuracy1: 0.991576 | loss2: 0.031286  accuracy2: 0.988990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 80.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.073595  accuracy1: 0.983619 | loss2: 0.048271  accuracy2: 0.984375\n",
      "-------------\n",
      "Epoch 29:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:16<00:00, 34.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.022173  accuracy1: 0.992215 | loss2: 0.030829  accuracy2: 0.988573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 77.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.073494  accuracy1: 0.984375 | loss2: 0.055236  accuracy2: 0.981603\n",
      "-------------\n",
      "Epoch 30:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:16<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | loss1: 0.023195  accuracy1: 0.991993 | loss2: 0.029851  accuracy2: 0.989046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 84.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid | loss1: 0.076826  accuracy1: 0.984123 | loss2: 0.055838  accuracy2: 0.982611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 85.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss1: 0.074613  accuracy1: 0.981099  loss2: 0.088537   accuracy2: 0.974294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mnist.part2_twodigit.train_utils import batchify_data, run_epoch, train_model, Flatten\n",
    "import mnist.part2_twodigit.utils_multiMNIST as U\n",
    "path_to_data_dir = './mnist/Datasets/'\n",
    "use_mini_dataset = True\n",
    "\n",
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "num_classes = 10\n",
    "img_rows, img_cols = 42, 28 # input image dimensions\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(1, 32, (3,3))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d((2, 2))\n",
    "        self.conv_2 = nn.Conv2d(32, 64, (3, 3))\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = nn.Linear(2880, 64)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.linear2 = nn.Linear(64, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO use model layers to predict the two digits\n",
    "\n",
    "        x = self.conv_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        out_first_digit = x[:, :10]\n",
    "        out_second_digit = x[:, 10:]\n",
    "        return out_first_digit, out_second_digit\n",
    "\n",
    "def main():\n",
    "    X_train, y_train, X_test, y_test = U.get_data(path_to_data_dir, use_mini_dataset)\n",
    "\n",
    "    # Split into train and dev\n",
    "    dev_split_index = int(9 * len(X_train) / 10)\n",
    "    X_dev = X_train[dev_split_index:]\n",
    "    y_dev = [y_train[0][dev_split_index:], y_train[1][dev_split_index:]]\n",
    "    X_train = X_train[:dev_split_index]\n",
    "    y_train = [y_train[0][:dev_split_index], y_train[1][:dev_split_index]]\n",
    "\n",
    "    permutation = np.array([i for i in range(len(X_train))])\n",
    "    np.random.shuffle(permutation)\n",
    "    X_train = [X_train[i] for i in permutation]\n",
    "    y_train = [[y_train[0][i] for i in permutation], [y_train[1][i] for i in permutation]]\n",
    "\n",
    "    # Split dataset into batches\n",
    "    train_batches = batchify_data(X_train, y_train, batch_size)\n",
    "    dev_batches = batchify_data(X_dev, y_dev, batch_size)\n",
    "    test_batches = batchify_data(X_test, y_test, batch_size)\n",
    "\n",
    "    # Load model\n",
    "    input_dimension = img_rows * img_cols\n",
    "    model = CNN(input_dimension) # TODO add proper layers to CNN class above\n",
    "\n",
    "    # Train\n",
    "    train_model(train_batches, dev_batches, model)\n",
    "\n",
    "    ## Evaluate the model on test data\n",
    "    loss, acc = run_epoch(test_batches, model.eval(), None)\n",
    "    print('Test loss1: {:.6f}  accuracy1: {:.6f}  loss2: {:.6f}   accuracy2: {:.6f}'.format(loss[0], acc[0], loss[1], acc[1]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Specify seed for deterministic behavior, then shuffle. Do not change seed for official submissions to edx\n",
    "    np.random.seed(12321)  # for reproducibility\n",
    "    torch.manual_seed(12321)  # for reproducibility\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Machine_Learning_with_Python-7V858pgh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbf55fd141a929e96d217693ff943f340da010ee827d3bb7b01df8ee1539f1d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
