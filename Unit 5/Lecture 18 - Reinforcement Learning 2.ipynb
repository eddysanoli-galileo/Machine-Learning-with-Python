{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0) S: 1 / A: 1 / S': 1\n",
      "[[0.75 0.  ]\n",
      " [0.   0.  ]]\n",
      "(Epoch 1) S: 1 / A: 1 / S': 2\n",
      "[[-0.5625  0.    ]\n",
      " [ 0.      0.    ]]\n",
      "(Epoch 2) S: 2 / A: 2 / S': 1\n",
      "[[-0.5625  0.    ]\n",
      " [ 0.      0.75  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nptyping import NDArray, Float, Shape\n",
    "\n",
    "# State transition probabilities\n",
    "# Each element consists of the probability of moving from state S to S'\n",
    "T : NDArray[Shape[\"2, 2\"], Float] = np.array(\n",
    "    [  #  S1  S2\n",
    "        [0.1, 0.1], # S1'\n",
    "        [0.9, 0.9]  # S2'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rewards\n",
    "# Rewards for going from state S to state S'\n",
    "R : NDArray[Shape[\"2, 2\"], Float] = np.array(\n",
    "    [  #  S1  S2\n",
    "        [  1, -1],   # S1'\n",
    "        [ -1,  1]    # S2'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ===========================================\n",
    "# We want to estimate the transition probabilities and reward functions,\n",
    "# so the matrices defined above will just be for reference.\n",
    "\n",
    "# Initial Q value\n",
    "# NOTE: We have to specify the dtype of this array because, if we create\n",
    "# an array with just \"0\" and then try to assign to that specific value a float\n",
    "# numpy will simply ignore your request. Make sure the dtypes align.\n",
    "Q_hat : NDArray[Shape[\"2, 2\"], Float] = np.array(\n",
    "    [ #   S1   S2\n",
    "        [ 0.0, 0.0], # Action 1: Move to S1\n",
    "        [ 0.0, 0.0]  # Action 2: Move to S2\n",
    "    ]\n",
    ", dtype=float)  \n",
    "\n",
    "# Discount factor\n",
    "gamma : float = 0.5\n",
    "\n",
    "# Exponential moving average factor\n",
    "alpha : float = 0.75\n",
    "\n",
    "# Collected samples\n",
    "samples = np.array(\n",
    "    [  # S  S'  R\n",
    "        [1, 1,  1],\n",
    "        [1, 2, -1],\n",
    "        [2, 1,  1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Go through each sample\n",
    "for i, sample in enumerate(samples):\n",
    "\n",
    "    # Sample reward\n",
    "    R_s = sample[2]\n",
    "\n",
    "    # Sample \"Current\" state S\n",
    "    # We subtract 1 to make it \"indexing\" compatible\n",
    "    S : int = sample[0] - 1\n",
    "\n",
    "    # Sample \"Future\" state S'\n",
    "    # We subtract 1 to make it \"indexing\" compatible\n",
    "    S_prime : int = sample[1] - 1\n",
    "\n",
    "    # Action taken (Moved from state S)\n",
    "    A : int = sample[0] - 1\n",
    "\n",
    "    # Sample k\n",
    "    # (Maximizes Q value for the future state S')\n",
    "    S_k = R_s + gamma * np.max(Q_hat[S_prime, :])\n",
    "\n",
    "    # Iterate for the new Q value\n",
    "    # (Updates the value for the \"current action and state\" pair, Q(S, a))\n",
    "    Q_hat[A, S] = alpha * S_k + (1 - alpha) * Q_hat[A, S]\n",
    "\n",
    "    print(f\"(Epoch {i}) S: {S+1} / A: {A+1} / S': {S_prime+1}\")\n",
    "    print(Q_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Machine_Learning_with_Python-7V858pgh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbf55fd141a929e96d217693ff943f340da010ee827d3bb7b01df8ee1539f1d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
